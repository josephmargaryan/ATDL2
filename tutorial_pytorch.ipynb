{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Weight-Sharing for Neural Network Compression - PyTorch Tutorial\n",
    "\n",
    "This tutorial demonstrates the **Soft Weight-Sharing** approach from Ullrich, Meeds & Welling (ICLR 2017) using PyTorch.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Soft weight-sharing learns a Gaussian mixture model as an empirical prior over network weights. The key idea is that weights naturally cluster together during training, allowing us to:\n",
    "1. Replace individual weights with their cluster center (quantization)\n",
    "2. Store only cluster centers (codebook) + assignments\n",
    "3. Achieve high compression with minimal accuracy loss\n",
    "\n",
    "## Three-Phase Approach\n",
    "\n",
    "1. **PART 1: Pretrain** - Train a standard network on MNIST\n",
    "2. **PART 2: Retrain** - Retrain with a learned Gaussian mixture prior that encourages clustering\n",
    "3. **PART 3: Post-process** - Quantize weights to mixture means and evaluate compression\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import os\nimport json\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom tqdm import tqdm\n\n# Import our soft weight-sharing modules\nfrom sws.models import TutorialNet\nfrom sws.data import make_loaders\nfrom sws.prior import init_mixture, MixturePrior\nfrom sws.train import train_standard, retrain_soft_weight_sharing, evaluate\nfrom sws.compress import compression_report\nfrom sws.utils import collect_weight_params, set_seed, get_device\nfrom sws.viz import TrainingGifVisualizer\nfrom scripts.tutorial_helpers import (\n    plot_weight_scatter,\n    plot_weight_histogram,\n    plot_mixture_components,\n    plot_comparison_histograms\n)\n\n# Set random seed for reproducibility\nset_seed(42)\ndevice = get_device()\nprint(f\"Using device: {device}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load MNIST with batch size 128\n",
    "train_loader, test_loader, num_classes = make_loaders(\n",
    "    dataset=\"mnist\",\n",
    "    batch_size=128,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Test samples: {len(test_loader.dataset)}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 1: Pretrain Network\n",
    "\n",
    "We first train a standard convolutional neural network on MNIST:\n",
    "- **Architecture**: 2 convolutional layers + 2 fully-connected layers\n",
    "- **Parameters**: ~642,000 trainable weights\n",
    "- **Training**: Standard cross-entropy loss with Adam optimizer\n",
    "- **Expected accuracy**: ~98-99%"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "model = TutorialNet(num_classes=num_classes).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "weight_params = sum(p.numel() for p in collect_weight_params(model))\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Weight parameters (to be compressed): {weight_params:,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Pretrain for 20 epochs\n",
    "pretrain_acc = train_standard(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    epochs=10,\n",
    "    lr=1e-3,\n",
    "    wd=0.0,\n",
    "    optim_name=\"adam\",\n",
    "    eval_every=5,\n",
    "    desc=\"pretrain\"\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Pretrained model accuracy: {pretrain_acc:.4f} ({pretrain_acc*100:.2f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save the pretrained weights\n",
    "os.makedirs(\"tutorial_outputs2\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"tutorial_outputs2/pretrained_model.pt\")\n",
    "print(\"‚úì Saved pretrained model to tutorial_outputs2/pretrained_model.pt\")\n",
    "\n",
    "# Store pretrained weights for later comparison\n",
    "pretrained_weights = [w.clone() for w in collect_weight_params(model)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize pretrained weight distribution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_weight_histogram(\n",
    "    weights=pretrained_weights,\n",
    "    title=\"Pretrained Weight Distribution\",\n",
    "    log_scale=False,\n",
    "    save=\"tutorial_outputs2/pretrained_histogram.png\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 2: Retrain with Gaussian Mixture Prior\n",
    "\n",
    "Now we add a **Gaussian mixture prior** over the weights:\n",
    "\n",
    "$$p(w) = \\sum_{j=0}^{J-1} \\pi_j \\mathcal{N}(w | \\mu_j, \\sigma_j^2)$$\n",
    "\n",
    "Where:\n",
    "- **J = 16 components** (1 zero-spike + 15 non-zero clusters)\n",
    "- **œÄ‚ÇÄ = 0.99** (high probability on zero for sparsity)\n",
    "- **Œº‚ÇÄ = 0** (zero component is fixed)\n",
    "- **Œº‚ÇÅ...Œº‚ÇÅ‚ÇÖ** are learned from the pretrained weight distribution\n",
    "\n",
    "## Loss Function\n",
    "\n",
    "The training loss becomes:\n",
    "\n",
    "$$\\mathcal{L} = \\text{CrossEntropy}(y, \\hat{y}) + \\frac{\\tau}{N} \\sum_i -\\log p(w_i)$$\n",
    "\n",
    "Where:\n",
    "- **œÑ = 0.003** (complexity regularization strength)\n",
    "- **N = 60,000** (dataset size for proper normalization)\n",
    "\n",
    "The negative log probability term encourages weights to cluster at the mixture component means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Gaussian Mixture Prior"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize mixture with 16 components\n",
    "prior = init_mixture(\n",
    "    model=model,\n",
    "    J=16,  # Total components (1 zero + 15 non-zero)\n",
    "    pi0=0.99,  # High probability on zero component\n",
    "    init_means_mode=\"from_weights\",  # Initialize from pretrained weight range\n",
    "    init_sigma=0.25,  # Initial standard deviation\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Initialized Gaussian mixture prior\")\n",
    "print(f\"  - Number of components: {prior.J}\")\n",
    "print(f\"  - Zero component mixing weight (œÄ‚ÇÄ): {prior.pi0_init}\")\n",
    "\n",
    "# Visualize initial mixture\n",
    "mu, sigma2, pi = prior.mixture_params()\n",
    "print(f\"\\nInitial mixture means: {mu[:5].detach().cpu().numpy()}...\")\n",
    "print(f\"Initial mixture stds: {torch.sqrt(sigma2[:5]).detach().cpu().numpy()}...\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Setup GIF Visualizer\n\nWe'll use the `TrainingGifVisualizer` to create an animated visualization showing how weights evolve during retraining. The GIF will show:\n- Weight scatter plot (pretrained vs current weights)\n- Marginal histograms\n- Mixture component bands (mean ¬± 2œÉ)\n- Test accuracy per epoch",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Create GIF visualizer to track weight evolution during retraining\n",
    "viz = TrainingGifVisualizer(\n",
    "    out_dir=\"tutorial_outputs2\",\n",
    "    tag=\"retraining\",\n",
    "    framerate=2,\n",
    "    notebook_display = True,\n",
    "    cleanup_frames = True\n",
    ")\n",
    "\n",
    "print(\"‚úì GIF visualizer ready - will capture frames during training\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Retrain with Soft Weight-Sharing"
  },
  {
   "cell_type": "code",
   "source": [
    "# Retrain with mixture prior and GIF visualization\n",
    "retrain_acc = retrain_soft_weight_sharing(\n",
    "    model=model,\n",
    "    prior=prior,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    epochs=10,\n",
    "    lr_w=5e-4,  # Learning rate for network weights\n",
    "    lr_theta=3e-4,  # Learning rate for mixture parameters\n",
    "    weight_decay=0.0,\n",
    "    tau=0.003,  # Complexity regularization (properly normalized by dataset size)\n",
    "    tau_warmup_epochs=0,  # Gradually increase tau over first 10 epochs\n",
    "    complexity_mode=\"keras\",  # Use keras-style normalization (tau/dataset_size)\n",
    "    eval_every=10,\n",
    "    cr_every=0,  # Don't compute compression during training (slow)\n",
    "    mixture_every=0,  # Don't log mixture every epoch\n",
    "    run_dir=\"tutorial_outputs2\",\n",
    "    viz=viz  # Pass visualizer to capture frames during training\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Retrained model accuracy: {retrain_acc:.4f} ({retrain_acc*100:.2f}%)\")\n",
    "print(f\"  Accuracy drop from pretraining: {(pretrain_acc - retrain_acc)*100:.2f}%\")\n",
    "print(f\"\\n‚úì GIF animation saved to: tutorial_outputs2/retraining.gif\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### View the Training Animation\n\nThe GIF shows how weights migrate from their pretrained values (x-axis) toward mixture component means (y-axis) during retraining. You'll see:\n- Weights clustering into horizontal bands (the mixture components)\n- The marginal histogram becoming more sparse and discrete\n- Test accuracy tracked in the title",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display the GIF inline (works in Jupyter Lab/Notebook)\n",
    "from IPython.display import Image, display\n",
    "\n",
    "gif_path = \"tutorial_outputs2/retraining.gif\"\n",
    "if os.path.exists(gif_path):\n",
    "    display(Image(filename=gif_path))\n",
    "    print(f\"\\nüí° Animation also saved as individual frames in: tutorial_outputs2/retraining_frames/\")\n",
    "else:\n",
    "    print(f\"GIF not found at {gif_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save retrained (pre-quantized) model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save pre-quantized model\n",
    "torch.save(model.state_dict(), \"tutorial_outputs2/retrained_prequant_model.pt\")\n",
    "print(\"‚úì Saved retrained model to tutorial_outputs2/retrained_prequant_model.pt\")\n",
    "\n",
    "# Store retrained weights for comparison\n",
    "retrained_weights = [w.clone() for w in collect_weight_params(model)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize learned mixture components"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot the learned Gaussian mixture\n",
    "plot_mixture_components(\n",
    "    prior=prior,\n",
    "    xlim=(-0.5, 0.5),\n",
    "    save=\"tutorial_outputs2/learned_mixture.png\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize weight movement"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scatter plot showing how weights moved during retraining\n",
    "plot_weight_scatter(\n",
    "    weights_before=pretrained_weights,\n",
    "    weights_after=retrained_weights,\n",
    "    sample=20000,\n",
    "    xlim=(-0.5, 0.5),\n",
    "    ylim=(-0.5, 0.5),\n",
    "    save=\"tutorial_outputs2/weight_movement.png\"\n",
    ")\n",
    "\n",
    "print(\"\\nüí° Weights should cluster towards mixture component means (away from diagonal)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 3: Post-Processing and Compression\n",
    "\n",
    "Now we:\n",
    "1. **Quantize** weights by assigning each to its nearest mixture mean\n",
    "2. **Evaluate** the quantized model accuracy\n",
    "3. **Compute compression** using CSR + Huffman encoding\n",
    "\n",
    "## Quantization Strategy\n",
    "\n",
    "We use **maximum likelihood (ML) assignment**:\n",
    "- For each weight, find the component with highest likelihood\n",
    "- Replace weight with that component's mean\n",
    "- This avoids bias towards the zero-spike during snapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize weights to mixture means"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Quantize: snap each weight to its nearest mixture component mean\n",
    "prior.quantize_model(\n",
    "    model=model,\n",
    "    skip_last_matrix=True,  # Keep final classifier at full precision\n",
    "    assign=\"ml\"  # Use maximum likelihood assignment (avoids zero-spike bias)\n",
    ")\n",
    "\n",
    "print(\"‚úì Quantized weights to mixture means\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate quantized model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Evaluate accuracy after quantization\n",
    "quantized_acc = evaluate(model, test_loader, device)\n",
    "\n",
    "print(f\"\\nüìä Accuracy Comparison:\")\n",
    "print(f\"  Pretrained:  {pretrain_acc:.4f} ({pretrain_acc*100:.2f}%)\")\n",
    "print(f\"  Retrained:   {retrain_acc:.4f} ({retrain_acc*100:.2f}%)\")\n",
    "print(f\"  Quantized:   {quantized_acc:.4f} ({quantized_acc*100:.2f}%)\")\n",
    "print(f\"\\n  Total accuracy drop: {(pretrain_acc - quantized_acc)*100:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save quantized model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save final quantized model\n",
    "torch.save(model.state_dict(), \"tutorial_outputs2/quantized_model.pt\")\n",
    "print(\"‚úì Saved quantized model to tutorial_outputs2/quantized_model.pt\")\n",
    "\n",
    "# Store quantized weights\n",
    "quantized_weights = [w.clone() for w in collect_weight_params(model)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute compression statistics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Detailed compression report using CSR + Huffman encoding\n",
    "report = compression_report(\n",
    "    model=model,\n",
    "    prior=prior,\n",
    "    dataset=\"mnist\",\n",
    "    use_huffman=True,\n",
    "    pbits_fc=5,  # Bits for FC layer column index diffs\n",
    "    pbits_conv=8,  # Bits for Conv layer column index diffs\n",
    "    skip_last_matrix=True,  # Last layer was not quantized\n",
    "    assign_mode=\"ml\"  # Must match quantization assignment mode\n",
    ")\n",
    "\n",
    "print(\"\\nüóúÔ∏è  Compression Report:\")\n",
    "print(f\"  Original bits:    {report['orig_bits']:,}\")\n",
    "print(f\"  Compressed bits:  {report['compressed_bits']:,}\")\n",
    "print(f\"  Compression Ratio: {report['CR']:.2f}x\")\n",
    "print(f\"  Non-zero weights:  {report['nnz']:,} / {weight_params:,} ({100*report['nnz']/weight_params:.2f}%)\")\n",
    "print(f\"  Sparsity:         {100*(1 - report['nnz']/weight_params):.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer-wise compression breakdown"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nüìã Layer-wise Compression:\")\n",
    "print(f\"{'Layer':<15} {'Shape':<20} {'Original (bits)':<18} {'Compressed (bits)':<20} {'CR':<8} {'Sparsity':<10}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for layer_info in report['layers']:\n",
    "    if layer_info['passthrough']:\n",
    "        cr_str = \"N/A\"\n",
    "        sparsity = 0.0\n",
    "    else:\n",
    "        compressed = layer_info['bits_IR'] + layer_info['bits_IC'] + layer_info['bits_A'] + layer_info['bits_codebook']\n",
    "        cr = layer_info['orig_bits'] / max(compressed, 1)\n",
    "        cr_str = f\"{cr:.2f}x\"\n",
    "        total_weights = np.prod(layer_info['shape'])\n",
    "        sparsity = 100 * (1 - layer_info['nnz'] / total_weights)\n",
    "    \n",
    "    shape_str = 'x'.join(map(str, layer_info['shape']))\n",
    "    orig_str = f\"{layer_info['orig_bits']:,}\"\n",
    "    comp_str = f\"{layer_info['bits_IR'] + layer_info['bits_IC'] + layer_info['bits_A'] + layer_info['bits_codebook']:,}\"\n",
    "    \n",
    "    print(f\"{layer_info['layer']:<15} {shape_str:<20} {orig_str:<18} {comp_str:<20} {cr_str:<8} {sparsity:.1f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize weight distributions across all phases"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare histograms: pretrained ‚Üí retrained ‚Üí quantized\n",
    "plot_comparison_histograms(\n",
    "    weights_pre=pretrained_weights,\n",
    "    weights_retrained=retrained_weights,\n",
    "    weights_quantized=quantized_weights,\n",
    "    save_prefix=\"tutorial_outputs2/phase\"\n",
    ")\n",
    "\n",
    "print(\"\\nüí° Notice how weights progressively cluster and become sparse\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "We successfully applied soft weight-sharing to compress a neural network:\n",
    "\n",
    "### Results:\n",
    "- **Original model**: ~642K parameters at 32-bit ‚Üí ~20.5 MB\n",
    "- **Compressed model**: Achieves ~20-60x compression (depending on hyperparameters)\n",
    "- **Accuracy loss**: Typically < 1% on MNIST\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "1. **Soft clustering is better than hard**: By using a differentiable mixture prior, weights naturally migrate to cluster centers during training\n",
    "\n",
    "2. **Zero-spike induces sparsity**: The high mixing weight (œÄ‚ÇÄ = 0.99) on the zero component encourages many weights to become exactly zero\n",
    "\n",
    "3. **Proper normalization matters**: The complexity term must be normalized by dataset size (œÑ/N) for stable training\n",
    "\n",
    "4. **CSR + Huffman is efficient**: Sparse weights + entropy coding achieves better compression than naive approaches\n",
    "\n",
    "### Next Steps:\n",
    "- Try different number of components (J)\n",
    "- Experiment with different œÑ values\n",
    "- Apply to larger models (ResNets, etc.)\n",
    "- Combine with other compression techniques (pruning, quantization-aware training)\n",
    "\n",
    "---\n",
    "\n",
    "**Reference**: Ullrich, K., Meeds, E., & Welling, M. (2017). Soft Weight-Sharing for Neural Network Compression. *ICLR 2017*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Analyze Mixture Component Usage"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Count how many weights are assigned to each component\n",
    "mu, sigma2, pi = prior.mixture_params()\n",
    "mu = mu.detach().cpu().numpy()\n",
    "pi = pi.detach().cpu().numpy()\n",
    "\n",
    "# Count assignments in quantized model\n",
    "all_weights = torch.cat([w.flatten() for w in quantized_weights]).cpu().numpy()\n",
    "\n",
    "print(\"\\nüìä Component Assignment Statistics:\\n\")\n",
    "print(f\"{'Component':<12} {'Mean (Œº)':<12} {'Mixing (œÄ)':<12} {'# Weights':<15} {'Percentage':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for j in range(len(mu)):\n",
    "    # Count weights at this mean (with small tolerance for floating point)\n",
    "    count = np.sum(np.abs(all_weights - mu[j]) < 1e-6)\n",
    "    percentage = 100 * count / len(all_weights)\n",
    "    \n",
    "    comp_name = f\"Comp {j}\" if j > 0 else \"Zero-spike\"\n",
    "    print(f\"{comp_name:<12} {mu[j]:>11.4f} {pi[j]:>11.4f} {count:>14,} {percentage:>11.2f}%\")\n",
    "\n",
    "print(\"\\nüí° The zero-spike should capture most weights (high sparsity)\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
