{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e891a4-98ef-4bb6-84c8-f49181ee61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade pip\n",
    "!git clone -b feat/new_BO_protocol --single-branch https://github.com/josephmargaryan/ATDL2.git\n",
    "%cd ATDL2\n",
    "!pip install -e . --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o90ewvxdnq",
   "metadata": {},
   "source": [
    "# Pareto Multi-Objective Bayesian Optimization\n",
    "\n",
    "This notebook runs Bayesian optimization followed by full retraining with diagnostics.\n",
    "\n",
    "## Workflow\n",
    "1. **Bayesian Optimization**: Find Pareto-optimal hyperparameters\n",
    "2. **Visualize Pareto Front**: Inspect trade-offs between CR and accuracy\n",
    "3. **Full Retrain**: Use best parameters for complete training with diagnostics\n",
    "4. **Generate Plots**: Training curves, mixture dynamics, weight evolution GIF\n",
    "\n",
    "## Optimization Strategy\n",
    "- **Multi-objective**: Optimizes CR (Compression Rate) and Accuracy simultaneously\n",
    "- **Sampler**: NSGA-II (automatic for Pareto mode)\n",
    "- **Seed**: 42 (consistent across all runs)\n",
    "- **Output**: Pareto front of optimal trade-off solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lenet300-header",
   "metadata": {},
   "source": [
    "---\n",
    "# LeNet-300-100 Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lenet300-bo-header",
   "metadata": {},
   "source": [
    "## 1. Run Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lenet300-bo",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/tune_optuna.py \\\n",
    "    --preset lenet_300_100 \\\n",
    "    --use-pareto \\\n",
    "    --n-trials 50 \\\n",
    "    --save-dir runs/bo_pareto_lenet3002 \\\n",
    "    --load-pretrained runs/mnist_300/mnist_lenet_300_100_pre.pt \\\n",
    "    --pretrain-epochs 0 \\\n",
    "    --retrain-epochs 40 \\\n",
    "    --batch-size 128 \\\n",
    "    --num-workers 4 \\\n",
    "    --quant-skip-last \\\n",
    "    --eval-every 20 \\\n",
    "    --cr-every 20 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lenet300-viz-header",
   "metadata": {},
   "source": [
    "## 2. Visualize Pareto Front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lenet300-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/tune_optuna_pareto_viz.py \\\n",
    "    --pareto-json runs/bo_pareto_lenet3002/*_pareto_results.json \\\n",
    "    --annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lenet300-retrain-header",
   "metadata": {},
   "source": [
    "## 3. Full Retrain with Best Parameters\n",
    "\n",
    "**TODO**: After inspecting Pareto front, insert best hyperparameters below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lenet300-retrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Insert best hyperparameters from Pareto front\n",
    "BEST_TAU = \"<INSERT_VALUE>\"\n",
    "BEST_GAMMA_ALPHA = \"<INSERT_VALUE>\"\n",
    "BEST_GAMMA_BETA = \"<INSERT_VALUE>\"\n",
    "BEST_GAMMA_ALPHA_ZERO = \"<INSERT_VALUE>\"\n",
    "BEST_GAMMA_BETA_ZERO = \"<INSERT_VALUE>\"\n",
    "\n",
    "!python run_sws.py \\\n",
    "    --preset lenet_300_100 \\\n",
    "    --load-pretrained runs/mnist_300/mnist_lenet_300_100_pre.pt \\\n",
    "    --pretrain-epochs 0 \\\n",
    "    --retrain-epochs 100 \\\n",
    "    --tau {BEST_TAU} \\\n",
    "    --gamma-alpha {BEST_GAMMA_ALPHA} \\\n",
    "    --gamma-beta {BEST_GAMMA_BETA} \\\n",
    "    --gamma-alpha-zero {BEST_GAMMA_ALPHA_ZERO} \\\n",
    "    --gamma-beta-zero {BEST_GAMMA_BETA_ZERO} \\\n",
    "    --num-components 17 \\\n",
    "    --merge-kl-thresh 1e-10 \\\n",
    "    --quant-assign map \\\n",
    "    --complexity-mode keras \\\n",
    "    --tau-warmup-epochs 0 \\\n",
    "    --quant-skip-last \\\n",
    "    --batch-size 128 \\\n",
    "    --num-workers 4 \\\n",
    "    --eval-every 1 \\\n",
    "    --log-mixture-every 1 \\\n",
    "    --make-gif \\\n",
    "    --gif-fps 3 \\\n",
    "    --run-name lenet300_best_full \\\n",
    "    --save-dir runs/bo_pareto_lenet300 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lenet300-plots-header",
   "metadata": {},
   "source": [
    "## 4. Generate Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lenet300-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIR = \"runs/bo_pareto_lenet300/lenet300_best_full\"\n",
    "\n",
    "# Training curves (accuracy, loss, compression rate)\n",
    "!python scripts/plot_curves.py --run-dir {RUN_DIR}\n",
    "\n",
    "# Mixture evolution over epochs\n",
    "!python scripts/plot_mixture_dynamics.py --run-dir {RUN_DIR}\n",
    "\n",
    "# Weight scatter plot (w0 → wT movement)\n",
    "!python scripts/plot_weights_scatter.py --run-dir {RUN_DIR} --sample 20000\n",
    "\n",
    "# Final mixture + weight histogram\n",
    "!python scripts/plot_mixture.py --run-dir {RUN_DIR} --checkpoint prequant\n",
    "\n",
    "print(f\"\\n✓ All plots saved to {RUN_DIR}/figures/\")\n",
    "print(f\"✓ Training GIF saved to {RUN_DIR}/figures/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lenet5-header",
   "metadata": {},
   "source": [
    "---\n",
    "# LeNet5 Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lenet5-bo-header",
   "metadata": {},
   "source": [
    "## 1. Run Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lenet5-bo",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/tune_optuna.py \\\n",
    "      --preset lenet5 \\\n",
    "      --use-pareto \\\n",
    "      --n-trials 50 \\\n",
    "      --save-dir runs/bo_pareto_lenet52 \\\n",
    "      --load-pretrained runs/mnist_caffe/mnist_lenet5_pre.pt \\\n",
    "      --pretrain-epochs 0 \\\n",
    "      --retrain-epochs 40 \\\n",
    "      --batch-size 128 \\\n",
    "      --num-workers 4 \\\n",
    "      --quant-skip-last \\\n",
    "      --eval-every 20 \\\n",
    "      --cr-every 20 \\\n",
    "      --seed 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lenet5-viz-header",
   "metadata": {},
   "source": [
    "## 2. Visualize Pareto Front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lenet5-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/tune_optuna_pareto_viz.py \\\n",
    "    --pareto-json runs/bo_pareto_lenet52/*_pareto_results.json \\\n",
    "    --annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lenet5-retrain-header",
   "metadata": {},
   "source": [
    "## 3. Full Retrain with Best Parameters\n",
    "\n",
    "**TODO**: After inspecting Pareto front, insert best hyperparameters below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lenet5-retrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Insert best hyperparameters from Pareto front\n",
    "BEST_TAU = \"<INSERT_VALUE>\"\n",
    "BEST_GAMMA_ALPHA = \"<INSERT_VALUE>\"\n",
    "BEST_GAMMA_BETA = \"<INSERT_VALUE>\"\n",
    "BEST_GAMMA_ALPHA_ZERO = \"<INSERT_VALUE>\"\n",
    "BEST_GAMMA_BETA_ZERO = \"<INSERT_VALUE>\"\n",
    "\n",
    "!python run_sws.py \\\n",
    "    --preset lenet5 \\\n",
    "    --load-pretrained runs/mnist_caffe/mnist_lenet_5_caffe_pre.pt \\\n",
    "    --pretrain-epochs 0 \\\n",
    "    --retrain-epochs 100 \\\n",
    "    --tau {BEST_TAU} \\\n",
    "    --gamma-alpha {BEST_GAMMA_ALPHA} \\\n",
    "    --gamma-beta {BEST_GAMMA_BETA} \\\n",
    "    --gamma-alpha-zero {BEST_GAMMA_ALPHA_ZERO} \\\n",
    "    --gamma-beta-zero {BEST_GAMMA_BETA_ZERO} \\\n",
    "    --num-components 17 \\\n",
    "    --merge-kl-thresh 1e-10 \\\n",
    "    --quant-assign map \\\n",
    "    --complexity-mode keras \\\n",
    "    --tau-warmup-epochs 0 \\\n",
    "    --quant-skip-last \\\n",
    "    --batch-size 128 \\\n",
    "    --num-workers 4 \\\n",
    "    --eval-every 1 \\\n",
    "    --log-mixture-every 1 \\\n",
    "    --make-gif \\\n",
    "    --gif-fps 3 \\\n",
    "    --run-name lenet5_best_full \\\n",
    "    --save-dir runs/bo_pareto_lenet5 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lenet5-plots-header",
   "metadata": {},
   "source": [
    "## 4. Generate Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lenet5-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIR = \"runs/bo_pareto_lenet5/lenet5_best_full\"\n",
    "\n",
    "# Training curves (accuracy, loss, compression rate)\n",
    "!python scripts/plot_curves.py --run-dir {RUN_DIR}\n",
    "\n",
    "# Mixture evolution over epochs\n",
    "!python scripts/plot_mixture_dynamics.py --run-dir {RUN_DIR}\n",
    "\n",
    "# Weight scatter plot (w0 → wT movement)\n",
    "!python scripts/plot_weights_scatter.py --run-dir {RUN_DIR} --sample 20000\n",
    "\n",
    "# Convolutional filters (pre vs quantized)\n",
    "!python scripts/plot_filters.py --run-dir {RUN_DIR} --checkpoint pre\n",
    "!python scripts/plot_filters.py --run-dir {RUN_DIR} --checkpoint quantized\n",
    "\n",
    "# Final mixture + weight histogram\n",
    "!python scripts/plot_mixture.py --run-dir {RUN_DIR} --checkpoint prequant\n",
    "\n",
    "print(f\"\\n✓ All plots saved to {RUN_DIR}/figures/\")\n",
    "print(f\"✓ Training GIF saved to {RUN_DIR}/figures/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
