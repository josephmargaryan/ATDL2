{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Full SWS Compression with Optimized Hyperpriors' parameters\n",
    "\n",
    "Run complete soft weight-sharing retraining with hyperparameters selected from Pareto front exploration.\n",
    "\n",
    "## Workflow\n",
    "1. **Fill in hyperparameters** (from `BO.ipynb` Pareto front)\n",
    "2. **Run full retraining** (100 epochs with diagnostics)\n",
    "3. **Generate all plots** (GIF, training curves, mixture dynamics, etc.)\n",
    "4. **Analyze compression** (layer-wise breakdown, sparsity, CR)\n",
    "\n",
    "## Instructions\n",
    "- **Step 1**: Run `BO.ipynb` to find Pareto-optimal hyperparameters\n",
    "- **Step 2**: Select a solution from the Pareto front\n",
    "- **Step 3**: Copy hyperparameters to the cell below\n",
    "- **Step 4**: Run all cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. User Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "user-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# USER: Fill in these values from Pareto front exploration (BO.ipynb)\n",
    "# ========================================\n",
    "\n",
    "# Model selection\n",
    "MODEL = \"lenet_300_100\"  # Options: \"lenet_300_100\", \"lenet5\", \"wrn_16_4\"\n",
    "DATASET = \"mnist\"        # Options: \"mnist\", \"cifar10\"\n",
    "\n",
    "# Hyperparameters from Pareto front (REQUIRED - fill these in!)\n",
    "TAU = None                # Example: 0.005\n",
    "GAMMA_ALPHA = None        # Example: 250.0\n",
    "GAMMA_BETA = None         # Example: 0.15\n",
    "GAMMA_ALPHA_ZERO = None   # Example: 4500.0\n",
    "GAMMA_BETA_ZERO = None    # Example: 2.5\n",
    "\n",
    "# ========================================\n",
    "# Validation (do not modify)\n",
    "# ========================================\n",
    "\n",
    "assert TAU is not None, \"ERROR: Please set TAU (complexity regularization)\"\n",
    "assert GAMMA_ALPHA is not None, \"ERROR: Please set GAMMA_ALPHA (Gamma prior shape for non-zero components)\"\n",
    "assert GAMMA_BETA is not None, \"ERROR: Please set GAMMA_BETA (Gamma prior rate for non-zero components)\"\n",
    "assert GAMMA_ALPHA_ZERO is not None, \"ERROR: Please set GAMMA_ALPHA_ZERO (Gamma prior shape for zero component)\"\n",
    "assert GAMMA_BETA_ZERO is not None, \"ERROR: Please set GAMMA_BETA_ZERO (Gamma prior rate for zero component)\"\n",
    "\n",
    "print(\"‚úÖ All hyperparameters validated\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Model:              {MODEL}\")\n",
    "print(f\"  Dataset:            {DATASET}\")\n",
    "print(f\"\\n  Hyperparameters:\")\n",
    "print(f\"    tau:              {TAU:.6g}\")\n",
    "print(f\"    gamma_alpha:      {GAMMA_ALPHA:.6g}\")\n",
    "print(f\"    gamma_beta:       {GAMMA_BETA:.6g}\")\n",
    "print(f\"    gamma_alpha_zero: {GAMMA_ALPHA_ZERO:.6g}\")\n",
    "print(f\"    gamma_beta_zero:  {GAMMA_BETA_ZERO:.6g}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint-header",
   "metadata": {},
   "source": [
    "### Map Model to Pretrained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checkpoint-map",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect checkpoint path based on model and dataset\n",
    "CHECKPOINT_MAP = {\n",
    "    (\"lenet_300_100\", \"mnist\"): \"checkpoints/mnist_lenet_300_100_pre.pt\",\n",
    "    (\"lenet5\", \"mnist\"): \"checkpoints/mnist_lenet5_pre.pt\",\n",
    "    (\"wrn_16_4\", \"cifar10\"): \"checkpoints/cifar10_wrn_16_4_pre.pt\",\n",
    "}\n",
    "\n",
    "CHECKPOINT = CHECKPOINT_MAP.get((MODEL, DATASET))\n",
    "assert CHECKPOINT is not None, f\"Unknown model/dataset combination: {MODEL}/{DATASET}\"\n",
    "\n",
    "import os\n",
    "if not os.path.exists(CHECKPOINT):\n",
    "    print(f\"‚ö†Ô∏è  WARNING: Checkpoint not found: {CHECKPOINT}\")\n",
    "    print(f\"   Please run training.ipynb first to create baseline checkpoints.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Loading pretrained checkpoint: {CHECKPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Run SWS with Custom Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-cmd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build command with user-specified parameters\n",
    "cmd = f\"\"\"python run_sws.py \\\\\n",
    "    --preset {MODEL} \\\\\n",
    "    --load-pretrained {CHECKPOINT} \\\\\n",
    "    --pretrain-epochs 0 \\\\\n",
    "    --retrain-epochs 100 \\\\\n",
    "    --tau {TAU} \\\\\n",
    "    --gamma-alpha {GAMMA_ALPHA} \\\\\n",
    "    --gamma-beta {GAMMA_BETA} \\\\\n",
    "    --gamma-alpha-zero {GAMMA_ALPHA_ZERO} \\\\\n",
    "    --gamma-beta-zero {GAMMA_BETA_ZERO} \\\\\n",
    "    --num-components 17 \\\\\n",
    "    --merge-kl-thresh 1e-10 \\\\\n",
    "    --quant-assign map \\\\\n",
    "    --complexity-mode keras \\\\\n",
    "    --tau-warmup-epochs 0 \\\\\n",
    "    --quant-skip-last \\\\\n",
    "    --batch-size 128 \\\\\n",
    "    --num-workers 4 \\\\\n",
    "    --eval-every 1 \\\\\n",
    "    --log-mixture-every 1 \\\\\n",
    "    --make-gif \\\\\n",
    "    --gif-fps 3 \\\\\n",
    "    --run-name {MODEL}_compression \\\\\n",
    "    --save-dir compression_results \\\\\n",
    "    --seed 42\"\"\"\n",
    "\n",
    "print(\"Command to execute:\")\n",
    "print(\"=\"*80)\n",
    "print(cmd)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute training\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rundir-header",
   "metadata": {},
   "source": [
    "### Set Run Directory for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "set-rundir",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIR = f\"compression_results/{MODEL}_compression\"\n",
    "print(f\"Results directory: {RUN_DIR}\")\n",
    "\n",
    "# Verify it exists\n",
    "if os.path.exists(RUN_DIR):\n",
    "    print(f\"‚úÖ Run directory found\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Run directory not found. Training may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plots-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Generate All Diagnostic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curves-header",
   "metadata": {},
   "source": [
    "### Training Curves (Accuracy, Loss, Compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/plot_curves.py --run-dir {RUN_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mixture-header",
   "metadata": {},
   "source": [
    "### Mixture Evolution Over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-mixture-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/plot_mixture_dynamics.py --run-dir {RUN_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scatter-header",
   "metadata": {},
   "source": [
    "### Weight Movement (Pretrained ‚Üí Retrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-scatter",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/plot_weights_scatter.py --run-dir {RUN_DIR} --sample 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-mixture-header",
   "metadata": {},
   "source": [
    "### Final Mixture Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/plot_mixture.py --run-dir {RUN_DIR} --checkpoint prequant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "display-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Display Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gif-header",
   "metadata": {},
   "source": [
    "### Training Evolution GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-gif",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "gif_path = f\"{RUN_DIR}/figures/retraining.gif\"\n",
    "if os.path.exists(gif_path):\n",
    "    print(\"Training Evolution Animation:\")\n",
    "    display(Image(filename=gif_path))\n",
    "    print(f\"\\nüí° Animation shows weight evolution over 100 epochs\")\n",
    "    print(f\"   Weights migrate from pretrained values toward mixture component means\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  GIF not found at {gif_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "### Compression Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load summary metrics\n",
    "summary_file = f\"{RUN_DIR}/summary_paper_metrics.json\"\n",
    "if os.path.exists(summary_file):\n",
    "    with open(summary_file) as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL RESULTS - COMPRESSION WITH CUSTOM HYPERPARAMETERS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nüìä ACCURACY METRICS:\")\n",
    "    print(f\"  Pretrain accuracy:    {summary['acc_pretrain']:.4f} ({summary['acc_pretrain']*100:.2f}%)\")\n",
    "    print(f\"  Retrain accuracy:     {summary['acc_retrain']:.4f} ({summary['acc_retrain']*100:.2f}%)\")\n",
    "    print(f\"  Quantized accuracy:   {summary['acc_quantized']:.4f} ({summary['acc_quantized']*100:.2f}%)\")\n",
    "    print(f\"  Total accuracy drop:  {summary['Delta[%]']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüíæ COMPRESSION METRICS:\")\n",
    "    print(f\"  Compression Ratio:    {summary['CR']:.2f}x\")\n",
    "    print(f\"  Total parameters:     {int(summary['|W|']):,}\")\n",
    "    print(f\"  Non-zero params:      {summary['|W_nonzero|/|W|[%]']:.2f}%\")\n",
    "    print(f\"  Sparsity:             {100 - summary['|W_nonzero|/|W|[%]']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüîß HYPERPARAMETERS USED:\")\n",
    "    print(f\"  tau:                  {TAU:.6g}\")\n",
    "    print(f\"  gamma_alpha:          {GAMMA_ALPHA:.6g}\")\n",
    "    print(f\"  gamma_beta:           {GAMMA_BETA:.6g}\")\n",
    "    print(f\"  gamma_alpha_zero:     {GAMMA_ALPHA_ZERO:.6g}\")\n",
    "    print(f\"  gamma_beta_zero:      {GAMMA_BETA_ZERO:.6g}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Summary file not found: {summary_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "report-header",
   "metadata": {},
   "source": [
    "### Detailed Compression Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_file = f\"{RUN_DIR}/report.json\"\n",
    "if os.path.exists(report_file):\n",
    "    with open(report_file) as f:\n",
    "        report = json.load(f)\n",
    "    \n",
    "    print(\"\\nüìã DETAILED COMPRESSION REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Original bits:        {report['orig_bits']:,}\")\n",
    "    print(f\"Compressed bits:      {report['compressed_bits']:,}\")\n",
    "    print(f\"Compression Ratio:    {report['CR']:.2f}x\")\n",
    "    print(f\"Non-zero weights:     {report['nnz']:,}\")\n",
    "    print(f\"Dataset:              {report.get('dataset', 'N/A')}\")\n",
    "    print(f\"Huffman encoding:     {report.get('use_huffman', False)}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Report file not found: {report_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "layer-header",
   "metadata": {},
   "source": [
    "### Layer-wise Compression Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-layers",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(report_file):\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"\\nüìä LAYER-WISE COMPRESSION:\")\n",
    "    print(f\"{'Layer':<15} {'Shape':<20} {'Original (bits)':<18} {'Compressed (bits)':<20} {'CR':<8} {'Sparsity':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for layer_info in report['layers']:\n",
    "        if layer_info.get('passthrough', False):\n",
    "            cr_str = \"N/A\"\n",
    "            sparsity = 0.0\n",
    "        else:\n",
    "            compressed = (layer_info['bits_IR'] + layer_info['bits_IC'] + \n",
    "                         layer_info['bits_A'] + layer_info['bits_codebook'])\n",
    "            cr = layer_info['orig_bits'] / max(compressed, 1)\n",
    "            cr_str = f\"{cr:.2f}x\"\n",
    "            total_weights = np.prod(layer_info['shape'])\n",
    "            sparsity = 100 * (1 - layer_info['nnz'] / total_weights)\n",
    "        \n",
    "        shape_str = 'x'.join(map(str, layer_info['shape']))\n",
    "        orig_str = f\"{layer_info['orig_bits']:,}\"\n",
    "        comp_str = f\"{layer_info['bits_IR'] + layer_info['bits_IC'] + layer_info['bits_A'] + layer_info['bits_codebook']:,}\"\n",
    "        \n",
    "        print(f\"{layer_info['layer']:<15} {shape_str:<20} {orig_str:<18} {comp_str:<20} {cr_str:<8} {sparsity:.1f}%\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "files-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. List All Generated Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüìÅ Generated files in {RUN_DIR}:\")\n",
    "print(\"=\"*80)\n",
    "!ls -lh {RUN_DIR}\n",
    "\n",
    "print(f\"\\nüìÅ Diagnostic plots in {RUN_DIR}/figures:\")\n",
    "print(\"=\"*80)\n",
    "!ls -lh {RUN_DIR}/figures/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Successfully completed SWS compression with custom hyperparameters!\n",
    "\n",
    "### Outputs:\n",
    "- **Models**: \n",
    "  - Pretrained: `{RUN_DIR}/{DATASET}_{MODEL}_pre.pt`\n",
    "  - Pre-quantized: `{RUN_DIR}/{DATASET}_{MODEL}_prequant.pt`\n",
    "  - Quantized: `{RUN_DIR}/{DATASET}_{MODEL}_quantized.pt`\n",
    "\n",
    "- **Diagnostics**:\n",
    "  - Training GIF: `{RUN_DIR}/figures/retraining.gif`\n",
    "  - Training curves: `{RUN_DIR}/figures/plot_curves.png`\n",
    "  - Mixture dynamics: `{RUN_DIR}/figures/plot_mixture_dynamics.png`\n",
    "  - Weight scatter: `{RUN_DIR}/figures/plot_weights_scatter.png`\n",
    "  - Final mixture: `{RUN_DIR}/figures/plot_mixture_prequant.png`\n",
    "\n",
    "- **Reports**:\n",
    "  - Compression report: `{RUN_DIR}/report.json`\n",
    "  - Summary metrics: `{RUN_DIR}/summary_paper_metrics.json`\n",
    "  - Layer pruning: `{RUN_DIR}/layer_pruning.json`\n",
    "  - Training log: `{RUN_DIR}/metrics.csv`\n",
    "\n",
    "### Next Steps:\n",
    "- Compare results with `no_hyperpriors.ipynb` baseline\n",
    "- Try different hyperparameters from the Pareto front\n",
    "- Apply to other models (LeNet5, WRN-16-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
